{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e23eff",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bfc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c44eac",
   "metadata": {},
   "source": [
    "## 1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c734d032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3eb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8639fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\"><span class=\"mw-page-title-main\">Main Page</span></h1>\n",
      "<h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "<h2>Navigation menu</h2>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span class=\"vector-menu-heading-label\">Views</span>\n",
      "</h3>\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span class=\"vector-menu-heading-label\">Navigation</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span class=\"vector-menu-heading-label\">Contribute</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span class=\"vector-menu-heading-label\">Tools</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span class=\"vector-menu-heading-label\">Print/export</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span class=\"vector-menu-heading-label\">In other projects</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span class=\"vector-menu-heading-label\">Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "header_tags = soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "print(*header_tags, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f39fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53d041ca",
   "metadata": {},
   "source": [
    "## 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8ae2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&count=100')\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf06ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(imdb.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a50c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = soup.find_all(\"div\", class_='lister-item-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c326ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name=[]\n",
    "release_year=[]\n",
    "rating =[]\n",
    "\n",
    "for i in total:\n",
    "    name = i.h3.a.text\n",
    "    movie_name.append(name)\n",
    "for i in total:\n",
    "    year_of_release = i.h3.find('span', class_ = 'lister-item-year text-muted unbold').text.replace('(','').replace(')','').replace(' ','') \n",
    "    release_year.append(year_of_release)\n",
    "for i in total:\n",
    "    rat = i.div.find('div', class_='inline-block ratings-imdb-rating').get('data-value')\n",
    "    rating.append(rat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159b257",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b6d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = pd.DataFrame({'Movie_Name':movie_name, 'Year_of_Release':release_year, 'Rating':rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75a85fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>1993</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>1958</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>1952</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>1941</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>1931</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Movie_Name Year_of_Release Rating\n",
       "0                        The Shawshank Redemption            1994    9.3\n",
       "1                                   The Godfather            1972    9.2\n",
       "2                                 The Dark Knight            2008      9\n",
       "3   The Lord of the Rings: The Return of the King            2003      9\n",
       "4                                Schindler's List            1993      9\n",
       "..                                            ...             ...    ...\n",
       "95                             North by Northwest            1959    8.3\n",
       "96                                        Vertigo            1958    8.3\n",
       "97                            Singin' in the Rain            1952    8.3\n",
       "98                                   Citizen Kane            1941    8.3\n",
       "99              M - Eine Stadt sucht einen Mörder            1931    8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9facb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f69d665",
   "metadata": {},
   "source": [
    "## 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216dd38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_indian = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "ind_soup = BeautifulSoup(imdb_indian.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d361c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = []\n",
    "ratings=[]\n",
    "year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d40984",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ind_soup.find_all('td',class_='titleColumn'):\n",
    "    name = i.find('a').text\n",
    "    movies.append(name)\n",
    "movies = movies[:100]\n",
    "for i in ind_soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "    rating = i.find('strong').text\n",
    "    ratings.append(rating)\n",
    "ratings = ratings[:100]\n",
    "for i in ind_soup.find_all('td',class_='titleColumn'):\n",
    "    yor = i.find('span',class_='secondaryInfo').text.replace('(','').replace(')','').replace(' ','')\n",
    "    year.append(yor)\n",
    "year = year[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8686a113",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dfa7dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>YOR</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kantara</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>1993</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ustad Hotel</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Theeran Adhigaaram Ondru</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Angoor</td>\n",
       "      <td>1982</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title   YOR Rating\n",
       "0                               Kantara  2022    8.6\n",
       "1   Ramayana: The Legend of Prince Rama  1993    8.5\n",
       "2            Rocketry: The Nambi Effect  2022    8.4\n",
       "3                            Anbe Sivam  2003    8.4\n",
       "4                               Nayakan  1987    8.4\n",
       "..                                  ...   ...    ...\n",
       "95                          Ustad Hotel  2012    8.0\n",
       "96             Theeran Adhigaaram Ondru  2017    8.0\n",
       "97                      Rang De Basanti  2006    8.0\n",
       "98          Baahubali 2: The Conclusion  2017    8.0\n",
       "99                               Angoor  1982    8.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indian = pd.DataFrame({'Title':movies, 'YOR':year, 'Rating':ratings})\n",
    "top_indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071d605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9f44f5a",
   "metadata": {},
   "source": [
    "## 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d81bfb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_pre = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "pres_soup = BeautifulSoup(ind_pre.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1e57337",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "Term_of_Office=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e94e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pres_soup.find_all('div', class_='presidentListing'):\n",
    "    name = i.find('h3').text.split('(')[0]\n",
    "    names.append(name)\n",
    "for i in pres_soup.find_all('div', class_='presidentListing'):\n",
    "    duration = i.find('p').text.split(':')[1]\n",
    "    Term_of_Office.append(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2239a0",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e6ed317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the President</th>\n",
       "      <th>Term-of-Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name of the President  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term-of-Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_prez = pd.DataFrame({'Name of the President':names, 'Term-of-Office':Term_of_Office})\n",
    "indian_prez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1b569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ddf1d6",
   "metadata": {},
   "source": [
    "## 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#### a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "#### b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "#### c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585ce89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06788697",
   "metadata": {},
   "source": [
    "#### a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdcbc51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "odi_soup = BeautifulSoup(odi_page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bb14285",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "matches=[]\n",
    "points=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1a91a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in odi_soup.find_all('span',class_='u-show-phablet'):\n",
    "    names=i.text\n",
    "    name.append(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e3610cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstmatch = []\n",
    "firstpoint = []\n",
    "firstrating =[]\n",
    "\n",
    "first= odi_soup.find('td',class_='rankings-block__banner--matches').text\n",
    "firstmatch.append(first)\n",
    "\n",
    "firstp= odi_soup.find('td',class_='rankings-block__banner--points').text\n",
    "firstpoint.append(firstp)\n",
    "\n",
    "firstr= odi_soup.find('td',class_='rankings-block__banner--rating u-text-right').text.strip()\n",
    "firstrating.append(firstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffb4587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_mat_points = []\n",
    "for i in odi_soup.find_all('td', class_='table-body__cell u-center-text'):\n",
    "    match = i.text\n",
    "    rem_mat_points.append(match)\n",
    "\n",
    "rem_mat = rem_mat_points[0:38:2]\n",
    "rem_poi = rem_mat_points[1:38:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bc1183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_rat = []\n",
    "for i in odi_soup.find_all('td',class_= 'table-body__cell u-text-right rating'):\n",
    "    ratings = i.text\n",
    "    rem_rat.append(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c36b9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = firstmatch+rem_mat\n",
    "points = firstpoint+rem_poi\n",
    "rating = firstrating + rem_rat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a56076",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4346fae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZ</td>\n",
       "      <td>22</td>\n",
       "      <td>2,508</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IND</td>\n",
       "      <td>34</td>\n",
       "      <td>3,802</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAK</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUS</td>\n",
       "      <td>29</td>\n",
       "      <td>3,071</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SA</td>\n",
       "      <td>24</td>\n",
       "      <td>2,392</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAN</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SL</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WI</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFG</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IRE</td>\n",
       "      <td>23</td>\n",
       "      <td>1,214</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SCO</td>\n",
       "      <td>27</td>\n",
       "      <td>1,254</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ZIM</td>\n",
       "      <td>26</td>\n",
       "      <td>1,098</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NAM</td>\n",
       "      <td>19</td>\n",
       "      <td>642</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NED</td>\n",
       "      <td>21</td>\n",
       "      <td>673</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UAE</td>\n",
       "      <td>22</td>\n",
       "      <td>697</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OMA</td>\n",
       "      <td>30</td>\n",
       "      <td>919</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USA</td>\n",
       "      <td>27</td>\n",
       "      <td>641</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NEP</td>\n",
       "      <td>22</td>\n",
       "      <td>331</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PNG</td>\n",
       "      <td>26</td>\n",
       "      <td>209</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team Matches Points Rating\n",
       "0   ENG      27  3,226    119\n",
       "1    NZ      22  2,508    114\n",
       "2   IND      34  3,802    112\n",
       "3   PAK      22  2,354    107\n",
       "4   AUS      29  3,071    106\n",
       "5    SA      24  2,392    100\n",
       "6   BAN      30  2,753     92\n",
       "7    SL      29  2,658     92\n",
       "8    WI      41  2,902     71\n",
       "9   AFG      18  1,238     69\n",
       "10  IRE      23  1,214     53\n",
       "11  SCO      27  1,254     46\n",
       "12  ZIM      26  1,098     42\n",
       "13  NAM      19    642     34\n",
       "14  NED      21    673     32\n",
       "15  UAE      22    697     32\n",
       "16  OMA      30    919     31\n",
       "17  USA      27    641     24\n",
       "18  NEP      22    331     15\n",
       "19  PNG      26    209      8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI = pd.DataFrame({'Team':name, 'Matches':matches, 'Points':points, 'Rating':rating})\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1671b56",
   "metadata": {},
   "source": [
    "#### b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "853d61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_bat = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "bat_soup = BeautifulSoup(odi_bat.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84aa475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "team=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eed9fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname = []\n",
    "firstteam = []\n",
    "firstrating =[]\n",
    "\n",
    "first= bat_soup.find('div',class_='rankings-block__banner--name-large').text\n",
    "firstname.append(first)\n",
    "\n",
    "firstt= bat_soup.find('div',class_='rankings-block__banner--nationality').text.strip()\n",
    "firstteam.append(firstt)\n",
    "\n",
    "firstr= bat_soup.find('div',class_='rankings-block__banner--rating').text\n",
    "firstrating.append(firstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c38683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_names = []\n",
    "for i in bat_soup.find_all('td', class_='table-body__cell rankings-table__name name'):\n",
    "    rem_names.append(i.a.text)\n",
    "top_2to10 = rem_names[:9]\n",
    "\n",
    "rem_teams=[]\n",
    "for i in bat_soup.find_all('span', class_='table-body__logo-text'):\n",
    "    rem_teams.append(i.text)\n",
    "top_2to10teams = rem_teams[:9]\n",
    "\n",
    "rem_ratings=[]\n",
    "for i in bat_soup.find_all('td', class_='table-body__cell rating'):\n",
    "    rem_ratings.append(i.text)\n",
    "top_2to10rat = rem_ratings[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99c536f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=firstname+top_2to10\n",
    "team=firstteam+top_2to10teams\n",
    "rating=firstrating+top_2to10rat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56899c",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dba1848f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team Rating\n",
       "0             Babar Azam  PAK    890\n",
       "1            Imam-ul-Haq  PAK    779\n",
       "2  Rassie van der Dussen   SA    766\n",
       "3        Quinton de Kock   SA    759\n",
       "4         Jonny Bairstow  ENG    732\n",
       "5           David Warner  AUS    725\n",
       "6            Virat Kohli  IND    722\n",
       "7           Rohit Sharma  IND    718\n",
       "8            Ross Taylor   NZ    701\n",
       "9            Steve Smith  AUS    697"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BAT = pd.DataFrame({'Player':name, 'Team':team,'Rating':rating})\n",
    "BAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e127a",
   "metadata": {},
   "source": [
    "#### c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d239e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_bowl = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "bowl_soup = BeautifulSoup(odi_bowl.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "609c7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "team=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b55d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname = []\n",
    "firstteam = []\n",
    "firstrating =[]\n",
    "\n",
    "first= bowl_soup.find('div',class_='rankings-block__banner--name-large').text\n",
    "firstname.append(first)\n",
    "\n",
    "firstt= bowl_soup.find('div',class_='rankings-block__banner--nationality').text.strip()\n",
    "firstteam.append(firstt)\n",
    "\n",
    "firstr= bowl_soup.find('div',class_='rankings-block__banner--rating').text\n",
    "firstrating.append(firstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0ba8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_names = []\n",
    "for i in bowl_soup.find_all('td', class_='table-body__cell rankings-table__name name'):\n",
    "    rem_names.append(i.a.text)\n",
    "top_2to10 = rem_names[:9]\n",
    "\n",
    "rem_teams=[]\n",
    "for i in bowl_soup.find_all('span', class_='table-body__logo-text'):\n",
    "    rem_teams.append(i.text)\n",
    "top_2to10teams = rem_teams[:9]\n",
    "\n",
    "rem_ratings=[]\n",
    "for i in bowl_soup.find_all('td', class_='table-body__cell rating'):\n",
    "    rem_ratings.append(i.text)\n",
    "top_2to10rat = rem_ratings[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54d5a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=firstname+top_2to10\n",
    "team=firstteam+top_2to10teams\n",
    "rating=firstrating+top_2to10rat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c78c0",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd32f263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0       Trent Boult   NZ    775\n",
       "1    Josh Hazlewood  AUS    718\n",
       "2  Mujeeb Ur Rahman  AFG    676\n",
       "3    Shaheen Afridi  PAK    661\n",
       "4     Mohammad Nabi  AFG    657\n",
       "5      Mehedi Hasan  BAN    655\n",
       "6        Matt Henry   NZ    654\n",
       "7    Mitchell Starc  AUS    653\n",
       "8       Rashid Khan  AFG    651\n",
       "9    Jasprit Bumrah  IND    642"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOWL = pd.DataFrame({'Player':name, 'Team':team,'Rating':rating})\n",
    "BOWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed40f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "489739f8",
   "metadata": {},
   "source": [
    "## 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#### a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "#### b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "#### c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4552f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25bb23f6",
   "metadata": {},
   "source": [
    "#### a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6da7b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "odi_soup = BeautifulSoup(odi_page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b991cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "matches=[]\n",
    "points=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34b074c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in odi_soup.find_all('span',class_='u-show-phablet'):\n",
    "    names=i.text\n",
    "    name.append(names)\n",
    "name = name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0a4776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstmatch = []\n",
    "firstpoint = []\n",
    "firstrating =[]\n",
    "\n",
    "first= odi_soup.find('td',class_='rankings-block__banner--matches').text\n",
    "firstmatch.append(first)\n",
    "\n",
    "firstp= odi_soup.find('td',class_='rankings-block__banner--points').text\n",
    "firstpoint.append(firstp)\n",
    "\n",
    "firstr= odi_soup.find('td',class_='rankings-block__banner--rating u-text-right').text.strip()\n",
    "firstrating.append(firstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da5df720",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_mat_points = []\n",
    "for i in odi_soup.find_all('td', class_='table-body__cell u-center-text'):\n",
    "    match = i.text\n",
    "    rem_mat_points.append(match)\n",
    "\n",
    "rem_mat = rem_mat_points[0:20:2]\n",
    "rem_poi = rem_mat_points[1:20:2]\n",
    "\n",
    "rem_mat = rem_mat[:9]\n",
    "rem_poi = rem_poi[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd210da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_rat = []\n",
    "for i in odi_soup.find_all('td',class_= 'table-body__cell u-text-right rating'):\n",
    "    ratings = i.text\n",
    "    rem_rat.append(ratings)\n",
    "rem_rat = rem_rat[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ff023da",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = firstmatch+rem_mat\n",
    "points = firstpoint+rem_poi\n",
    "rating = firstrating + rem_rat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4ca9d",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ff052d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUS</td>\n",
       "      <td>18</td>\n",
       "      <td>3,061</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG</td>\n",
       "      <td>25</td>\n",
       "      <td>2,904</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IND</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NZ</td>\n",
       "      <td>24</td>\n",
       "      <td>2,425</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WI</td>\n",
       "      <td>24</td>\n",
       "      <td>2,334</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAN</td>\n",
       "      <td>12</td>\n",
       "      <td>932</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAK</td>\n",
       "      <td>21</td>\n",
       "      <td>1,237</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IRE</td>\n",
       "      <td>11</td>\n",
       "      <td>516</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SL</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team Matches Points Rating\n",
       "0  AUS      18  3,061    170\n",
       "1   SA      26  3,098    119\n",
       "2  ENG      25  2,904    116\n",
       "3  IND      27  2,820    104\n",
       "4   NZ      24  2,425    101\n",
       "5   WI      24  2,334     97\n",
       "6  BAN      12    932     78\n",
       "7  PAK      21  1,237     59\n",
       "8  IRE      11    516     47\n",
       "9   SL       8    353     44"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOM_ODI = pd.DataFrame({'Team':name, 'Matches':matches, 'Points':points, 'Rating':rating})\n",
    "WOM_ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd9b8e",
   "metadata": {},
   "source": [
    "#### b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c394fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_bat = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "bat_soup = BeautifulSoup(odi_bat.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82298e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "team=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b4c5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname = []\n",
    "firstteam = []\n",
    "firstrating =[]\n",
    "\n",
    "first= bat_soup.find('div',class_='rankings-block__banner--name-large').text\n",
    "firstname.append(first)\n",
    "\n",
    "firstt= bat_soup.find('div',class_='rankings-block__banner--nationality').text.strip()\n",
    "firstteam.append(firstt)\n",
    "\n",
    "firstr= bat_soup.find('div',class_='rankings-block__banner--rating').text\n",
    "firstrating.append(firstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d3f2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_names = []\n",
    "for i in bat_soup.find_all('td', class_='table-body__cell rankings-table__name name'):\n",
    "    rem_names.append(i.a.text)\n",
    "top_2to10 = rem_names[:9]\n",
    "\n",
    "rem_teams=[]\n",
    "for i in bat_soup.find_all('span', class_='table-body__logo-text'):\n",
    "    rem_teams.append(i.text)\n",
    "top_2to10teams = rem_teams[:9]\n",
    "\n",
    "rem_ratings=[]\n",
    "for i in bat_soup.find_all('td', class_='table-body__cell rating'):\n",
    "    rem_ratings.append(i.text)\n",
    "top_2to10rat = rem_ratings[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffeecd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=firstname+top_2to10\n",
    "team=firstteam+top_2to10teams\n",
    "rating=firstrating+top_2to10rat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100b356",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4520e33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team Rating\n",
       "0         Alyssa Healy  AUS    785\n",
       "1          Beth Mooney  AUS    749\n",
       "2      Laura Wolvaardt   SA    732\n",
       "3       Natalie Sciver  ENG    725\n",
       "4     Harmanpreet Kaur  IND    716\n",
       "5      Smriti Mandhana  IND    714\n",
       "6          Meg Lanning  AUS    710\n",
       "7       Rachael Haynes  AUS    701\n",
       "8    Amy Satterthwaite   NZ    661\n",
       "9  Chamari Athapaththu   SL    655"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOM_BAT = pd.DataFrame({'Player':name, 'Team':team,'Rating':rating})\n",
    "WOM_BAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c6120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "963be806",
   "metadata": {},
   "source": [
    "#### c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b586840",
   "metadata": {},
   "outputs": [],
   "source": [
    "wom_odi_ar = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "ar_soup = BeautifulSoup(wom_odi_ar.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57ed6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "team=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "244dbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname = []\n",
    "firstteam = []\n",
    "firstrating =[]\n",
    "\n",
    "first= ar_soup.find('div',class_='rankings-block__banner--name-large').text\n",
    "firstname.append(first)\n",
    "\n",
    "firstt= ar_soup.find('div',class_='rankings-block__banner--nationality').text.strip()\n",
    "firstteam.append(firstt)\n",
    "\n",
    "firstr= ar_soup.find('div',class_='rankings-block__banner--rating').text\n",
    "firstrating.append(firstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e772093",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_names = []\n",
    "for i in ar_soup.find_all('td', class_='table-body__cell rankings-table__name name'):\n",
    "    rem_names.append(i.a.text)\n",
    "top_2to10 = rem_names[:9]\n",
    "\n",
    "rem_teams=[]\n",
    "for i in ar_soup.find_all('span', class_='table-body__logo-text'):\n",
    "    rem_teams.append(i.text)\n",
    "top_2to10teams = rem_teams[:9]\n",
    "\n",
    "rem_ratings=[]\n",
    "for i in ar_soup.find_all('td', class_='table-body__cell rating'):\n",
    "    rem_ratings.append(i.text)\n",
    "top_2to10rat = rem_ratings[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27991043",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=firstname+top_2to10\n",
    "team=firstteam+top_2to10teams\n",
    "rating=firstrating+top_2to10rat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573b218",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81264518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0   Hayley Matthews   WI    380\n",
       "1      Ellyse Perry  AUS    374\n",
       "2    Natalie Sciver  ENG    357\n",
       "3       Amelia Kerr   NZ    356\n",
       "4    Marizanne Kapp   SA    349\n",
       "5     Deepti Sharma  IND    322\n",
       "6  Ashleigh Gardner  AUS    270\n",
       "7     Jess Jonassen  AUS    246\n",
       "8    Jhulan Goswami  IND    214\n",
       "9   Katherine Brunt  ENG    207"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOM_AR = pd.DataFrame({'Player':name, 'Team':team,'Rating':rating})\n",
    "WOM_AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c180b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d3aa0f9",
   "metadata": {},
   "source": [
    "## 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "#### i) Headline\n",
    "#### ii) Time\n",
    "#### iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "578fc722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18 Min Ago</td>\n",
       "      <td>Chipotle Mexican Grill's earnings top estimate...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/chipotle-mexic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35 Min Ago</td>\n",
       "      <td>Your last chance to secure 9.62% annual intere...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/you-must-buy-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45 Min Ago</td>\n",
       "      <td>Leading Economic Index: What it is and why its...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/leading-econom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47 Min Ago</td>\n",
       "      <td>Ex-Trump aide Meadows asks judge to block Geor...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/trump-aide-mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58 Min Ago</td>\n",
       "      <td>Halliburton's earnings beat points to more ups...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/halliburtons-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58 Min Ago</td>\n",
       "      <td>Americans say they will need $1.25 million to ...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/americans-say-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>New Covid-19 'Scrabble' variants: Here's every...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/covid-19-scrab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>Apple puts more ads in the iPhone's App Store</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/apple-puts-mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>'No clear answer.' How to decide between Roth,...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/when-a-roth-or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>People who had mild Covid had increased risk o...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/people-who-cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>3 ETFs to buy if earnings confirm the bottom i...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/3-etfs-to-buy-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>If this trend can hold up, it would spell good...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/if-this-trend-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>Hawaii couple charged with securities fraud ov...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/hawaii-couple-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>Fake billionaire, Harvard MBA grad poseur deni...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/fugitive-justi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>Excessively cheap stocks that you can buy now,...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/excessively-ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>GOP groups spend $6.2 million in Oz-Fetterman ...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/pennsylvania-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>Airlines have the passengers. Now they need th...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/airlines-have-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>Stocks making the biggest moves midday: Xerox,...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>These Big Tech earnings could help answer a ke...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/this-latest-ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>Gates' climate-tech firm will put more money i...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/bill-gates-cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>One EV maker is best positioned as the group t...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/one-ev-maker-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>South Korea, U.S. in 'intense conversation' ov...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/ira-ev-tax-cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>3 takeaways from our daily meeting: Halliburto...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/takeaways-from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>World Series tickets for games in Philadelphia...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/how-much-world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>Education Dept. to reduce 'red tape' for publi...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/education-depa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>This energy storage name can rally 60% from In...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/this-under-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>Canopy Growth to speed up entry into U.S. cann...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/canopy-to-spee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>Walmart, Disney among top employers that laid ...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/nations-12-lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>Arizona GOP governor hopeful Kari Lake draws c...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/arizona-govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>Stocks could get a lift from this huge buying ...</td>\n",
       "      <td>https://www.cnbc.com/2022/10/25/stocks-could-g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time                                          Headlines  \\\n",
       "0    18 Min Ago  Chipotle Mexican Grill's earnings top estimate...   \n",
       "1    35 Min Ago  Your last chance to secure 9.62% annual intere...   \n",
       "2    45 Min Ago  Leading Economic Index: What it is and why its...   \n",
       "3    47 Min Ago  Ex-Trump aide Meadows asks judge to block Geor...   \n",
       "4    58 Min Ago  Halliburton's earnings beat points to more ups...   \n",
       "5    58 Min Ago  Americans say they will need $1.25 million to ...   \n",
       "6   2 Hours Ago  New Covid-19 'Scrabble' variants: Here's every...   \n",
       "7   2 Hours Ago      Apple puts more ads in the iPhone's App Store   \n",
       "8   2 Hours Ago  'No clear answer.' How to decide between Roth,...   \n",
       "9   2 Hours Ago  People who had mild Covid had increased risk o...   \n",
       "10  2 Hours Ago  3 ETFs to buy if earnings confirm the bottom i...   \n",
       "11  2 Hours Ago  If this trend can hold up, it would spell good...   \n",
       "12  3 Hours Ago  Hawaii couple charged with securities fraud ov...   \n",
       "13  3 Hours Ago  Fake billionaire, Harvard MBA grad poseur deni...   \n",
       "14  3 Hours Ago  Excessively cheap stocks that you can buy now,...   \n",
       "15  3 Hours Ago  GOP groups spend $6.2 million in Oz-Fetterman ...   \n",
       "16  4 Hours Ago  Airlines have the passengers. Now they need th...   \n",
       "17  4 Hours Ago  Stocks making the biggest moves midday: Xerox,...   \n",
       "18  4 Hours Ago  These Big Tech earnings could help answer a ke...   \n",
       "19  4 Hours Ago  Gates' climate-tech firm will put more money i...   \n",
       "20  4 Hours Ago  One EV maker is best positioned as the group t...   \n",
       "21  4 Hours Ago  South Korea, U.S. in 'intense conversation' ov...   \n",
       "22  4 Hours Ago  3 takeaways from our daily meeting: Halliburto...   \n",
       "23  4 Hours Ago  World Series tickets for games in Philadelphia...   \n",
       "24  5 Hours Ago  Education Dept. to reduce 'red tape' for publi...   \n",
       "25  5 Hours Ago  This energy storage name can rally 60% from In...   \n",
       "26  5 Hours Ago  Canopy Growth to speed up entry into U.S. cann...   \n",
       "27  5 Hours Ago  Walmart, Disney among top employers that laid ...   \n",
       "28  6 Hours Ago  Arizona GOP governor hopeful Kari Lake draws c...   \n",
       "29  6 Hours Ago  Stocks could get a lift from this huge buying ...   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2022/10/25/chipotle-mexic...  \n",
       "1   https://www.cnbc.com/2022/10/25/you-must-buy-s...  \n",
       "2   https://www.cnbc.com/2022/10/25/leading-econom...  \n",
       "3   https://www.cnbc.com/2022/10/25/trump-aide-mar...  \n",
       "4   https://www.cnbc.com/2022/10/25/halliburtons-e...  \n",
       "5   https://www.cnbc.com/2022/10/25/americans-say-...  \n",
       "6   https://www.cnbc.com/2022/10/25/covid-19-scrab...  \n",
       "7   https://www.cnbc.com/2022/10/25/apple-puts-mor...  \n",
       "8   https://www.cnbc.com/2022/10/25/when-a-roth-or...  \n",
       "9   https://www.cnbc.com/2022/10/25/people-who-cau...  \n",
       "10  https://www.cnbc.com/2022/10/25/3-etfs-to-buy-...  \n",
       "11  https://www.cnbc.com/2022/10/25/if-this-trend-...  \n",
       "12  https://www.cnbc.com/2022/10/25/hawaii-couple-...  \n",
       "13  https://www.cnbc.com/2022/10/25/fugitive-justi...  \n",
       "14  https://www.cnbc.com/2022/10/25/excessively-ch...  \n",
       "15  https://www.cnbc.com/2022/10/25/pennsylvania-s...  \n",
       "16  https://www.cnbc.com/2022/10/25/airlines-have-...  \n",
       "17  https://www.cnbc.com/2022/10/25/stocks-making-...  \n",
       "18  https://www.cnbc.com/2022/10/25/this-latest-ra...  \n",
       "19  https://www.cnbc.com/2022/10/25/bill-gates-cli...  \n",
       "20  https://www.cnbc.com/2022/10/25/one-ev-maker-i...  \n",
       "21  https://www.cnbc.com/2022/10/25/ira-ev-tax-cre...  \n",
       "22  https://www.cnbc.com/2022/10/25/takeaways-from...  \n",
       "23  https://www.cnbc.com/2022/10/25/how-much-world...  \n",
       "24  https://www.cnbc.com/2022/10/25/education-depa...  \n",
       "25  https://www.cnbc.com/2022/10/25/this-under-the...  \n",
       "26  https://www.cnbc.com/2022/10/25/canopy-to-spee...  \n",
       "27  https://www.cnbc.com/2022/10/25/nations-12-lar...  \n",
       "28  https://www.cnbc.com/2022/10/25/arizona-govern...  \n",
       "29  https://www.cnbc.com/2022/10/25/stocks-could-g...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnbc_page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "cnbc_soup = BeautifulSoup(cnbc_page.content)\n",
    "\n",
    "time =[]\n",
    "headline=[]\n",
    "linktonews=[]\n",
    "\n",
    "for i in cnbc_soup.find_all('time', class_='LatestNews-timestamp'):\n",
    "    time.append(i.text)\n",
    "\n",
    "for i in cnbc_soup.find_all('a',class_='LatestNews-headline'):\n",
    "    headline.append(i.text)\n",
    "\n",
    "for i in cnbc_soup.find_all('div', class_='LatestNews-headlineWrapper'):\n",
    "    linktonews.append(i.find('a', class_='LatestNews-headline').get('href'))\n",
    "\n",
    "NEWS = pd.DataFrame({'Time':time,'Headlines':headline,'Link':linktonews})\n",
    "NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d833b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc0623de",
   "metadata": {},
   "source": [
    "## 8). Write a python program to scrape the details of most downloaded articles from AI in last 90 days. https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "### Scrape below mentioned details :\n",
    "#### i) Paper Title\n",
    "#### ii) Authors\n",
    "#### iii) Published Date\n",
    "#### iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0749e448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ttle</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Ttle  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors            Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journals_page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "ai_soup = BeautifulSoup(journals_page.content)\n",
    "\n",
    "title =[]\n",
    "authors=[]\n",
    "date=[]\n",
    "url=[]\n",
    "\n",
    "for i in ai_soup.find_all('h2', class_='sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR'):\n",
    "    title.append(i.text)\n",
    "\n",
    "for i in ai_soup.find_all('span',class_='sc-1w3fpd7-0 pgLAT'):\n",
    "    authors.append(i.text)\n",
    "\n",
    "for i in ai_soup.find_all('span', class_='sc-1thf9ly-2 bKddwo'):\n",
    "    date.append(i.span.text)\n",
    "\n",
    "for i in ai_soup.find_all('li', class_='sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp'):\n",
    "    url.append(i.find('a', class_='sc-5smygv-0 nrDZj').get('href'))\n",
    "\n",
    "AIJOUR = pd.DataFrame({'Ttle':title,'Authors':authors,'Date':date,'Link':url})\n",
    "AIJOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85bf75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "051f5942",
   "metadata": {},
   "source": [
    "## 9). Write a python program to scrape mentioned details from dineout.co.in :\n",
    "#### i) Restaurant name\n",
    "#### ii) Cuisine\n",
    "#### iii) Location\n",
    "#### iv) Ratings\n",
    "#### v) Image URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8415c1",
   "metadata": {},
   "source": [
    "### For 1st Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c580674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pages = np.arange(1,312)\n",
    "\n",
    "names=[]\n",
    "cuisine=[]\n",
    "price =[]\n",
    "location = []\n",
    "ratings = []\n",
    "images = []\n",
    "\n",
    "\n",
    "page = requests.get('https://www.dineout.co.in/bangalore-restaurants')\n",
    "soup = BeautifulSoup(page.text)\n",
    "for i in soup.find_all('a',class_ = 'restnt-name ellipsis'):\n",
    "    names.append(i.text)\n",
    "for i in soup.find_all('span',class_ = 'double-line-ellipsis'):\n",
    "    price.append(i.text.split(')')[0] +')')\n",
    "for i in soup.find_all('span',class_ = 'double-line-ellipsis'):\n",
    "    cuisine.append(i.text.split(')')[1].replace('|',''))\n",
    "for i in soup.find_all('div',class_ = 'restnt-loc ellipsis'):\n",
    "    location.append(i.text)\n",
    "for i in soup.find_all('div',class_ = {'restnt-rating rating-5','restnt-rating rating-4'}):\n",
    "    ratings.append(i.text)\n",
    "for i in soup.find_all('img',class_ = 'no-img'):\n",
    "    images.append(i.get('data-src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc38f8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Bier Library Brewery &amp; Kitchen</td>\n",
       "      <td>Continental, Finger Food, North Indian</td>\n",
       "      <td>Koramangala, South Bangalore</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uru Brewpark</td>\n",
       "      <td>North Indian, Italian, Continental, Asian</td>\n",
       "      <td>JP Nagar, South Bangalore</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hard Rock Cafe</td>\n",
       "      <td>Continental, American, Finger Food</td>\n",
       "      <td>St. Marks Road, Central Bangalore</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Bangalore Cafe</td>\n",
       "      <td>Continental, North Indian, Fast Food</td>\n",
       "      <td>Shanti Nagar, Central Bangalore</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toscano</td>\n",
       "      <td>Italian</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>4.5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biergarten</td>\n",
       "      <td>Continental, European</td>\n",
       "      <td>Koramangala, South Bangalore</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Badmaash</td>\n",
       "      <td>North Indian, Chettinad, Andhra, Biryani</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JW Kitchen</td>\n",
       "      <td>North Indian, Continental</td>\n",
       "      <td>JW Marriott Hotel,Vittal Mallya Road, Central ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Daddy</td>\n",
       "      <td>Asian, North Indian, European, Italian</td>\n",
       "      <td>Indiranagar, East Bangalore</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Raahi</td>\n",
       "      <td>Fusion</td>\n",
       "      <td>St. Marks Road, Central Bangalore</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cafe Noir</td>\n",
       "      <td>Continental, French, European, Health Food, ...</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cafe Azzure</td>\n",
       "      <td>Continental, Italian, Desserts, Bengali</td>\n",
       "      <td>MG Road, Central Bangalore</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Salt - Indian Restaurant Bar &amp; Grill</td>\n",
       "      <td>North Indian, Mughlai, South Indian</td>\n",
       "      <td>UB City, Central Bangalore</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sanchez</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1522 - The Pub</td>\n",
       "      <td>Continental, North Indian, Italian, Asian</td>\n",
       "      <td>Residency Road, Central Bangalore</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Easy Tiger</td>\n",
       "      <td>Finger Food</td>\n",
       "      <td>High Profile Building,Church Street, Central B...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>Japanese, Asian</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>No Limmits Lounge and Club</td>\n",
       "      <td>North Indian, Continental, Chinese</td>\n",
       "      <td>Allied Grand Plaza,Magrath Road, Central Banga...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Biere Club</td>\n",
       "      <td>Finger Food</td>\n",
       "      <td>Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Spice Terrace</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>JW Marriott Hotel,Vittal Mallya Road, Central ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Stories Brewery and Kitchen</td>\n",
       "      <td>Continental, Italian, Chinese, North Indian</td>\n",
       "      <td>BTM Layout, South Bangalore</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Restaurant_Name  \\\n",
       "0     The Bier Library Brewery & Kitchen   \n",
       "1                           Uru Brewpark   \n",
       "2                         Hard Rock Cafe   \n",
       "3                     The Bangalore Cafe   \n",
       "4                                Toscano   \n",
       "5                             Biergarten   \n",
       "6                               Badmaash   \n",
       "7                             JW Kitchen   \n",
       "8                                  Daddy   \n",
       "9                                  Raahi   \n",
       "10                             Cafe Noir   \n",
       "11                           Cafe Azzure   \n",
       "12  Salt - Indian Restaurant Bar & Grill   \n",
       "13                               Sanchez   \n",
       "14                        1522 - The Pub   \n",
       "15                            Easy Tiger   \n",
       "16                                 Shiro   \n",
       "17            No Limmits Lounge and Club   \n",
       "18                        The Biere Club   \n",
       "19                         Spice Terrace   \n",
       "20           Stories Brewery and Kitchen   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0              Continental, Finger Food, North Indian   \n",
       "1           North Indian, Italian, Continental, Asian   \n",
       "2                  Continental, American, Finger Food   \n",
       "3                Continental, North Indian, Fast Food   \n",
       "4                                             Italian   \n",
       "5                               Continental, European   \n",
       "6            North Indian, Chettinad, Andhra, Biryani   \n",
       "7                           North Indian, Continental   \n",
       "8              Asian, North Indian, European, Italian   \n",
       "9                                              Fusion   \n",
       "10    Continental, French, European, Health Food, ...   \n",
       "11            Continental, Italian, Desserts, Bengali   \n",
       "12                North Indian, Mughlai, South Indian   \n",
       "13                                            Mexican   \n",
       "14          Continental, North Indian, Italian, Asian   \n",
       "15                                        Finger Food   \n",
       "16                                    Japanese, Asian   \n",
       "17                 North Indian, Continental, Chinese   \n",
       "18                                        Finger Food   \n",
       "19                              North Indian, Mughlai   \n",
       "20        Continental, Italian, Chinese, North Indian   \n",
       "\n",
       "                                             Location Rating  \\\n",
       "0                        Koramangala, South Bangalore    4.4   \n",
       "1                           JP Nagar, South Bangalore    4.3   \n",
       "2                   St. Marks Road, Central Bangalore    4.4   \n",
       "3                     Shanti Nagar, Central Bangalore    4.3   \n",
       "4       UB City,Vittal Mallya Road, Central Bangalore    4.5   \n",
       "5                        Koramangala, South Bangalore    4.4   \n",
       "6       UB City,Vittal Mallya Road, Central Bangalore    4.2   \n",
       "7   JW Marriott Hotel,Vittal Mallya Road, Central ...    4.4   \n",
       "8                         Indiranagar, East Bangalore    4.2   \n",
       "9                   St. Marks Road, Central Bangalore      4   \n",
       "10      UB City,Vittal Mallya Road, Central Bangalore    4.4   \n",
       "11                         MG Road, Central Bangalore    4.3   \n",
       "12                         UB City, Central Bangalore    4.4   \n",
       "13      UB City,Vittal Mallya Road, Central Bangalore    4.3   \n",
       "14                  Residency Road, Central Bangalore    4.4   \n",
       "15  High Profile Building,Church Street, Central B...    4.2   \n",
       "16      UB City,Vittal Mallya Road, Central Bangalore    4.3   \n",
       "17  Allied Grand Plaza,Magrath Road, Central Banga...    3.7   \n",
       "18              Vittal Mallya Road, Central Bangalore    4.3   \n",
       "19  JW Marriott Hotel,Vittal Mallya Road, Central ...    4.2   \n",
       "20                        BTM Layout, South Bangalore    4.3   \n",
       "\n",
       "                                                Image  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RES = pd.DataFrame({'Restaurant_Name':names,'Cuisine':cuisine, 'Location':location,'Rating':ratings,'Image':images})\n",
    "RES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d40b23",
   "metadata": {},
   "source": [
    "## For multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5bbe60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pages = np.arange(1,312)\n",
    "\n",
    "names=[]\n",
    "cuisine=[]\n",
    "price =[]\n",
    "location = []\n",
    "images = []\n",
    "\n",
    "for page in pages:\n",
    "    page = requests.get('https://www.dineout.co.in/bangalore-restaurants?p='+str(page))\n",
    "    soup = BeautifulSoup(page.text)\n",
    "    for i in soup.find_all('a',class_ = 'restnt-name ellipsis'):\n",
    "        names.append(i.text)\n",
    "    for i in soup.find_all('span',class_ = 'double-line-ellipsis'):\n",
    "        price.append(i.text.split(')')[0] +')')\n",
    "    for i in soup.find_all('span',class_ = 'double-line-ellipsis'):\n",
    "        cuisine.append(i.text.split(')')[1].replace('|',''))\n",
    "    for i in soup.find_all('div',class_ = 'restnt-loc ellipsis'):\n",
    "        location.append(i.text)\n",
    "    for i in soup.find_all('img',class_ = 'no-img'):\n",
    "        images.append(i.get('data-src'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d74c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Bier Library Brewery &amp; Kitchen</td>\n",
       "      <td>Continental, Finger Food, North Indian</td>\n",
       "      <td>Koramangala, South Bangalore</td>\n",
       "      <td>₹ 1,900 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uru Brewpark</td>\n",
       "      <td>North Indian, Italian, Continental, Asian</td>\n",
       "      <td>JP Nagar, South Bangalore</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hard Rock Cafe</td>\n",
       "      <td>Continental, American, Finger Food</td>\n",
       "      <td>St. Marks Road, Central Bangalore</td>\n",
       "      <td>₹ 2,500 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Bangalore Cafe</td>\n",
       "      <td>Continental, North Indian, Fast Food</td>\n",
       "      <td>Shanti Nagar, Central Bangalore</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toscano</td>\n",
       "      <td>Italian</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>₹ 1,600 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6526</th>\n",
       "      <td>Epulo Vineyard Restaurant</td>\n",
       "      <td>North Indian, Continental</td>\n",
       "      <td>Bangalore Mysore Highway, South Bangalore</td>\n",
       "      <td>₹ 800 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6527</th>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast Food, Burger</td>\n",
       "      <td>Bangalore Mysore Highway, South Bangalore</td>\n",
       "      <td>₹ 500 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6528</th>\n",
       "      <td>Kailash Parbat</td>\n",
       "      <td>North Indian, Street Food</td>\n",
       "      <td>VV Mohalla, North Mysore</td>\n",
       "      <td>₹ 600 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>Infinity</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>The Zuri Whitefield,Whitefield, East Bangalore</td>\n",
       "      <td>₹ 2,700 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>Domino's Pizza</td>\n",
       "      <td>Pizza, Italian, Fast Food</td>\n",
       "      <td>Brookefield Mall,Brookefields, East Bangalore</td>\n",
       "      <td>₹ 500 for 2 (approx)</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6531 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Restaurant_Name  \\\n",
       "0     The Bier Library Brewery & Kitchen   \n",
       "1                           Uru Brewpark   \n",
       "2                         Hard Rock Cafe   \n",
       "3                     The Bangalore Cafe   \n",
       "4                                Toscano   \n",
       "...                                  ...   \n",
       "6526           Epulo Vineyard Restaurant   \n",
       "6527                          McDonald's   \n",
       "6528                      Kailash Parbat   \n",
       "6529                            Infinity   \n",
       "6530                      Domino's Pizza   \n",
       "\n",
       "                                          Cuisine  \\\n",
       "0          Continental, Finger Food, North Indian   \n",
       "1       North Indian, Italian, Continental, Asian   \n",
       "2              Continental, American, Finger Food   \n",
       "3            Continental, North Indian, Fast Food   \n",
       "4                                         Italian   \n",
       "...                                           ...   \n",
       "6526                    North Indian, Continental   \n",
       "6527                            Fast Food, Burger   \n",
       "6528                    North Indian, Street Food   \n",
       "6529                        North Indian, Mughlai   \n",
       "6530                    Pizza, Italian, Fast Food   \n",
       "\n",
       "                                            Location                   Price  \\\n",
       "0                       Koramangala, South Bangalore  ₹ 1,900 for 2 (approx)   \n",
       "1                          JP Nagar, South Bangalore  ₹ 2,000 for 2 (approx)   \n",
       "2                  St. Marks Road, Central Bangalore  ₹ 2,500 for 2 (approx)   \n",
       "3                    Shanti Nagar, Central Bangalore    ₹ 800 for 2 (approx)   \n",
       "4      UB City,Vittal Mallya Road, Central Bangalore  ₹ 1,600 for 2 (approx)   \n",
       "...                                              ...                     ...   \n",
       "6526       Bangalore Mysore Highway, South Bangalore    ₹ 800 for 2 (approx)   \n",
       "6527       Bangalore Mysore Highway, South Bangalore    ₹ 500 for 2 (approx)   \n",
       "6528                        VV Mohalla, North Mysore    ₹ 600 for 2 (approx)   \n",
       "6529  The Zuri Whitefield,Whitefield, East Bangalore  ₹ 2,700 for 2 (approx)   \n",
       "6530   Brookefield Mall,Brookefields, East Bangalore    ₹ 500 for 2 (approx)   \n",
       "\n",
       "                                                  Image  \n",
       "0     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4     https://im1.dineout.co.in/images/uploads/resta...  \n",
       "...                                                 ...  \n",
       "6526  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6527  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6528  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6529  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6530  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "\n",
       "[6531 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RES_ALL = pd.DataFrame({'Restaurant_Name':names,'Cuisine':cuisine, 'Location':location,'Price':price,'Image':images})\n",
    "RES_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e968d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73322cc8",
   "metadata": {},
   "source": [
    "## 10) Write a python program to scrape the details of top publications from Google Scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "#### i) Rank\n",
    "#### ii) Publication\n",
    "#### iii) h5-index\n",
    "#### iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15dffc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5_index</th>\n",
       "      <th>h5_median</th>\n",
       "      <th>h5_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "      <td>https://scholar.google.com//citations?hl=en&amp;oe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5_index  \\\n",
       "0     1.                                             Nature      444   \n",
       "1     2.                The New England Journal of Medicine      432   \n",
       "2     3.                                            Science      401   \n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389   \n",
       "4     5.                                         The Lancet      354   \n",
       "..   ...                                                ...      ...   \n",
       "95   96.                       Journal of Business Research      145   \n",
       "96   97.                                   Molecular Cancer      145   \n",
       "97   98.                                            Sensors      145   \n",
       "98   99.                              Nature Climate Change      144   \n",
       "99  100.                    IEEE Internet of Things Journal      144   \n",
       "\n",
       "   h5_median                                            h5_link  \n",
       "0        667  https://scholar.google.com//citations?hl=en&oe...  \n",
       "1        780  https://scholar.google.com//citations?hl=en&oe...  \n",
       "2        614  https://scholar.google.com//citations?hl=en&oe...  \n",
       "3        627  https://scholar.google.com//citations?hl=en&oe...  \n",
       "4        635  https://scholar.google.com//citations?hl=en&oe...  \n",
       "..       ...                                                ...  \n",
       "95       233  https://scholar.google.com//citations?hl=en&oe...  \n",
       "96       209  https://scholar.google.com//citations?hl=en&oe...  \n",
       "97       201  https://scholar.google.com//citations?hl=en&oe...  \n",
       "98       228  https://scholar.google.com//citations?hl=en&oe...  \n",
       "99       212  https://scholar.google.com//citations?hl=en&oe...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "soup = BeautifulSoup(page.text)\n",
    "\n",
    "rank = []\n",
    "publication =[]\n",
    "h5_index = []\n",
    "h5_median = []\n",
    "h5_link = []\n",
    "\n",
    "for i in soup.find_all('td',class_='gsc_mvt_p'):\n",
    "    rank.append(i.text)\n",
    "for i in soup.find_all('td',class_='gsc_mvt_t'):\n",
    "    publication.append(i.text)\n",
    "for i in soup.find_all('a',class_='gs_ibl gsc_mp_anchor'):\n",
    "    h5_index.append(i.text)\n",
    "for i in soup.find_all('a',class_='gs_ibl gsc_mp_anchor'):\n",
    "    h5_link.append('https://scholar.google.com/'+ str(i.get('href')))\n",
    "for i in soup.find_all('span',class_='gs_ibl gsc_mp_anchor'):\n",
    "    h5_median.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "PUB = pd.DataFrame({'Rank':rank, 'Publication':publication, 'h5_index':h5_index,'h5_median':h5_median,'h5_link':h5_link})\n",
    "PUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c0eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
